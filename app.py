import os
import json
import logging
import re
import time
import requests
from flask import Flask, request, jsonify, render_template

app = Flask(__name__)

# ===============================
# CONFIGURATION
# ===============================
with open("config.json", "r", encoding="utf-8") as f:
    config = json.load(f)

HF_MODEL_URL = config.get("hf_model_url")
MAX_NEW_TOKENS = config.get("max_new_tokens", 1000)
TEMPERATURE = config.get("temperature", 0.7)
HISTORY_FILE = config.get("history_file", "conversations.json")
KNOWLEDGE_FILE = config.get("knowledge_file", "knowledge_base.json")

# Param√®tres pour la compl√©tion du dernier mot
COMPLETION_MAX_NEW_TOKENS = config.get("completion_max_new_tokens", 20)
COMPLETION_TEMPERATURE = config.get("completion_temperature", 0.2)
MIN_WORD_LENGTH_FOR_TRUNCATION = config.get("min_word_length_for_truncation", 2)
MIN_TOTAL_LENGTH_FOR_TRUNCATION = config.get("min_total_length_for_truncation", 40)

HF_API_KEY = os.getenv("HF_API_KEY")
SERPAPI_API_KEY = os.getenv("SERPAPI_API_KEY")

if not HF_API_KEY or not SERPAPI_API_KEY:
    raise ValueError("Les variables HF_API_KEY et SERPAPI_API_KEY doivent √™tre d√©finies.")

HEADERS_HF = {"Authorization": f"Bearer {HF_API_KEY}"}

# ===============================
# LOGGING
# ===============================
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s [%(levelname)s] %(message)s',
                    handlers=[logging.FileHandler("app.log"), logging.StreamHandler()])

# ===============================
# HISTORIQUE & BASE DE CONNAISSANCES
# ===============================
conversation_history = []
if os.path.exists(HISTORY_FILE):
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            conversation_history = json.load(f)
    except Exception as e:
        logging.warning(f"Impossible de charger l'historique: {e}")

if os.path.exists(KNOWLEDGE_FILE):
    with open(KNOWLEDGE_FILE, "r", encoding="utf-8") as f:
        knowledge_base = json.load(f)
else:
    knowledge_base = {}

def save_history():
    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(conversation_history, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de l'historique: {e}")

def save_knowledge():
    try:
        with open(KNOWLEDGE_FILE, "w", encoding="utf-8") as f:
            json.dump(knowledge_base, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logging.error(f"Erreur lors de la sauvegarde de la base de connaissances: {e}")

# ===============================
# UTIL: d√©tection mot tronqu√© & compl√©tion
# ===============================
def is_last_word_truncated(text: str, min_word_length: int = MIN_WORD_LENGTH_FOR_TRUNCATION, min_total_length: int = MIN_TOTAL_LENGTH_FOR_TRUNCATION) -> bool:
    """
    Heuristique pour d√©tecter si le dernier mot semble tronqu√©.
    - Retourne True si :
      * le texte ne se termine pas par ponctuation (.!?‚Ä¶),
      * le texte est suffisamment long (>= min_total_length),
      * et le dernier token alphanum√©rique est tr√®s court (<= min_word_length),
      ou si on remarque un m√©lange lettre+chiffre incomplet √† la fin.
    """
    if not text or not isinstance(text, str):
        return False

    t = text.strip()

    # Si terminaison claire => pas tronqu√©
    if t.endswith(('.', '!', '?', '‚Ä¶', ';', ':')):
        return False

    # Si texte court -> tol√©rer
    if len(t) < min_total_length:
        return False

    # tokens alphanum√©riques
    tokens = re.findall(r"\w+", t, flags=re.UNICODE)
    if not tokens:
        return False

    last = tokens[-1]

    # Si dernier token est tr√®s court -> suspect
    if len(last) <= min_word_length:
        logging.debug(f"D√©tection truncation: dernier token court '{last}' (len={len(last)})")
        return True

    # Si m√©lange lettre+chiffre √† la fin -> suspect
    if re.search(r"[A-Za-z]\d$|\d[A-Za-z]$", last):
        logging.debug(f"D√©tection truncation: m√©lange suspect dans '{last}'")
        return True

    return False

def complete_last_word(hf_model_url: str, headers: dict, original_prompt: str, partial_text: str, max_new_tokens: int = COMPLETION_MAX_NEW_TOKENS) -> str | None:
    """
    Demande au mod√®le de compl√©ter uniquement le dernier mot du texte partiel.
    Retourne la compl√©tion (cha√Æne) ou None en cas d'√©chec.
    """
    # Construire un prompt court demandant uniquement la fin du dernier mot
    completion_prompt = (
        f"{original_prompt}\n\n"
        f"Le texte suivant s'est arr√™t√© en plein mot. Compl√®te uniquement le dernier mot pour que la phrase soit lisible.\n\n"
        f"Texte : \"{partial_text}\"\n\n"
        "R√©ponds uniquement par la suite n√©cessaire pour compl√©ter le dernier mot (ne r√©p√®te pas tout le texte)."
    )

    payload = {
        "inputs": completion_prompt,
        "parameters": {
            "max_new_tokens": max_new_tokens,
            "temperature": COMPLETION_TEMPERATURE,
            "top_p": 0.9,
            "do_sample": False
        }
    }

    try:
        resp = requests.post(hf_model_url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()

        # extraction robuste
        if isinstance(data, list) and "generated_text" in data[0]:
            cont = data[0]["generated_text"]
        elif isinstance(data, dict) and "generated_text" in data:
            cont = data.get("generated_text", "")
        else:
            logging.warning(f"Format inattendu de compl√©tion last word: {data}")
            return None

        cont = cont.strip()

        # Si le mod√®le renvoie le texte complet, essayer d'extraire seulement la portion en plus
        # Cherche la premi√®re occurrence de partial_text dans cont
        if cont.startswith(partial_text):
            extra = cont[len(partial_text):].lstrip()
            return extra if extra else None
        else:
            # Le mod√®le a renvoy√© juste la suite ‚Äî retourne tel quel
            return cont
    except Exception as e:
        logging.warning(f"√âchec compl√©tion du dernier mot: {e}")
        return None

# ===============================
# FONCTIONS D'APPEL HF / SERPAPI
# ===============================
def query_hf(prompt: str) -> str:
    """Interroge le mod√®le Hugging Face choisi et retourne le texte brut g√©n√©r√©."""
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": MAX_NEW_TOKENS,
            "temperature": TEMPERATURE,
            "top_p": 0.9,
            "do_sample": True
        }
    }
    try:
        response = requests.post(HF_MODEL_URL, headers=HEADERS_HF, json=payload, timeout=60)
        response.raise_for_status()
        data = response.json()

        # Selon le format renvoy√© par le mod√®le
        if isinstance(data, dict) and "generated_text" in data:
            return data["generated_text"]
        elif isinstance(data, list) and "generated_text" in data[0]:
            return data[0]["generated_text"]
        elif isinstance(data, dict) and "error" in data:
            logging.error(f"Erreur API Hugging Face : {data['error']}")
            return "Erreur lors de la g√©n√©ration de texte."
        else:
            logging.warning(f"R√©ponse inattendue Hugging Face : {data}")
            # Essayer de retourner une repr√©sentation textuelle si possible
            try:
                return str(data)
            except Exception:
                return "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse."
    except requests.Timeout:
        logging.error("‚è≥ Timeout Hugging Face")
        return "Le serveur Hugging Face met trop de temps √† r√©pondre."
    except requests.RequestException as e:
        logging.error(f"‚ö†Ô∏è Erreur r√©seau Hugging Face: {e}")
        return "Erreur de connexion √† Hugging Face."
    except Exception as e:
        logging.error(f"‚ö†Ô∏è Erreur inattendue Hugging Face: {e}")
        return "Une erreur est survenue lors du traitement."

def search_serapi(query: str) -> str:
    """Recherche sur le web via SerpAPI"""
    url = "https://serpapi.com/search"
    params = {"q": query, "hl": "fr", "gl": "fr", "api_key": SERPAPI_API_KEY}
    try:
        logging.info(f"üîç Requ√™te SerpAPI : {query}")
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        result = (
            data.get("answer_box", {}).get("answer") or
            data.get("answer_box", {}).get("snippet") or
            (data.get("organic_results") and data["organic_results"][0].get("snippet")) or
            ""
        )
        logging.info(f"‚úÖ R√©sultat SerpAPI : {result}")
        return result
    except requests.Timeout:
        logging.error("‚ö†Ô∏è Timeout SerpAPI")
        return "Erreur : le serveur de recherche met trop de temps √† r√©pondre."
    except requests.RequestException as e:
        logging.error(f"‚ö†Ô∏è Erreur r√©seau SerpAPI : {e}")
        return "Erreur de connexion √† SerpAPI."
    except Exception as e:
        logging.error(f"‚ö†Ô∏è Erreur inattendue SerpAPI : {e}")
        return "Erreur inattendue lors de la recherche."

# ===============================
# ROUTES FLASK
# ===============================
@app.route("/", methods=["GET"])
def home():
    return render_template("mesgbairai.html")

@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    user_input = data.get("message", "").strip()
    username = data.get("username", "Utilisateur")

    if not user_input:
        return jsonify({"error": "Message invalide"}), 400

    conversation_history.append({"role": "user", "name": username, "content": user_input})

    # 1Ô∏è‚É£ V√©rifier base de connaissances
    if user_input.lower() in knowledge_base:
        answer = knowledge_base[user_input.lower()]
        source = "exact"
    else:
        # 2Ô∏è‚É£ Rechercher sur le web
        web_answer = search_serapi(user_input)
        if web_answer and web_answer.strip() != "":
            # si SerpAPI retourne un texte trop court ou une erreur string, on laisse au mod√®le AI
            # ici on consid√®re web_answer valide si ce n'est pas un message d'erreur
            if web_answer.startswith("Erreur"):
                web_answer = ""  # ignorer ce r√©sultat pour fallback IA
            else:
                answer = web_answer
                source = "web"

        # si web_answer n'a pas fourni de contenu utile, on g√©n√®re via HF
        if not ('answer' in locals() and answer):
            history_text = "\n".join([f"{msg['name']} ({msg['role'].capitalize()}): {msg['content']}" 
                                      for msg in conversation_history])
            prompt = f"Tu es un assistant en C√¥te d'Ivoire qui lutte contre la d√©sinformation. R√©ponds de fa√ßon factuelle et claire.\n{history_text}\nAssistant:"
            # g√©n√©ration initiale
            generated = query_hf(prompt)
            source = "ai"

            # Si la r√©ponse ressemble √† un message d'erreur renvoy√© par query_hf -> on l'utilise telle quelle
            if generated.startswith("Erreur") or generated.startswith("D√©sol√©"):
                answer = generated
            else:
                # v√©rification du mot tronqu√©
                if is_last_word_truncated(generated):
                    logging.info("Mot tronqu√© d√©tect√© ‚Äî tentative de compl√©tion cibl√©e du dernier mot.")
                    extra = complete_last_word(HF_MODEL_URL, HEADERS_HF, prompt, generated, max_new_tokens=COMPLETION_MAX_NEW_TOKENS)
                    if extra:
                        # Joindre proprement
                        # si generated ne se termine pas par espace, assurer s√©paration correcte
                        if not generated.endswith(" "):
                            generated = generated + ""
                        generated = (generated + extra).strip()
                        # s'assurer de ponctuation finale
                        if not generated.endswith(('.', '?', '!', '‚Ä¶', ';', ':')):
                            generated = generated + "."
                    else:
                        logging.info("Aucune compl√©tion trouv√©e pour le dernier mot.")
                # finaliser la r√©ponse
                answer = generated

    conversation_history.append({"role": "assistant", "name": "Assistant", "content": answer})
    save_history()

    return jsonify({"response": answer, "source": source})

@app.route("/teach", methods=["POST"])
def teach():
    data = request.json
    question = data.get("question", "").strip()
    answer = data.get("answer", "").strip()

    if not question or not answer:
        return jsonify({"error": "Question et r√©ponse requises"}), 400

    knowledge_base[question.lower()] = answer
    save_knowledge()

    return jsonify({"message": "Nouvelle connaissance enregistr√©e ‚úÖ"})

# ===============================
# LANCEMENT
# ===============================
if __name__ == "__main__":
    app.run(debug=True)
